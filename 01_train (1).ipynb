{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2b71ca05",
      "metadata": {
        "id": "2b71ca05"
      },
      "source": [
        "\n",
        "# ü´Ä Heart Disease Prediction ‚Äì Training Pipeline (Complete Notebook)\n",
        "\n",
        "## Project Overview\n",
        "This project builds **two machine learning models** to predict the **10-year risk of Coronary Heart Disease (CHD)** using the *Framingham Heart Study* dataset.\n",
        "\n",
        "### Why two models?\n",
        "- **Model A**: Uses **all available features** ‚Üí higher accuracy, backend/clinical usage\n",
        "- **Model B**: Uses **limited, easy-to-collect features** ‚Üí lightweight, fast, frontend/mobile usage\n",
        "\n",
        "### Key Techniques Used\n",
        "- XGBoost (GPU accelerated)\n",
        "- Stratified Train/Test Split\n",
        "- Class imbalance handling\n",
        "- Hyperparameter tuning (RandomizedSearchCV)\n",
        "- Probability calibration (Sigmoid / Platt Scaling)\n",
        "- Custom threshold optimization (Recall-focused)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "301d62ae",
      "metadata": {
        "id": "301d62ae"
      },
      "source": [
        "\n",
        "## 1Ô∏è‚É£ Import Libraries\n",
        "We import:\n",
        "- Data handling libraries (NumPy, Pandas)\n",
        "- Scikit-learn tools for modeling, evaluation, calibration\n",
        "- XGBoost for high-performance gradient boosting\n",
        "- SciPy for hyperparameter distributions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "40e12cee",
      "metadata": {
        "id": "40e12cee"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    recall_score\n",
        ")\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from scipy.stats import randint, uniform, loguniform\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60c17875",
      "metadata": {
        "id": "60c17875"
      },
      "source": [
        "\n",
        "## 2Ô∏è‚É£ Load Dataset\n",
        "We load the Framingham Heart Study dataset.\n",
        "Target column:\n",
        "- **TenYearCHD** ‚Üí 1 = Heart disease within 10 years, 0 = No disease\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "56b62773",
      "metadata": {
        "id": "56b62773",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bd30e35-68dc-4ae9-de80-60f59f637f6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
            "0     1   39        4.0              0         0.0     0.0                0   \n",
            "1     0   46        2.0              0         0.0     0.0                0   \n",
            "2     1   48        1.0              1        20.0     0.0                0   \n",
            "3     0   61        3.0              1        30.0     0.0                0   \n",
            "4     0   46        3.0              1        23.0     0.0                0   \n",
            "\n",
            "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
            "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
            "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
            "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
            "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
            "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
            "\n",
            "   TenYearCHD  \n",
            "0           0  \n",
            "1           0  \n",
            "2           0  \n",
            "3           1  \n",
            "4           0  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "# using  github raw  link\n",
        "url = \"https://raw.githubusercontent.com/chetan-j123/Heart_decision_prediction_project/master/framingham_heart_study.csv\"\n",
        "data = pd.read_csv(url)\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5910bd93",
      "metadata": {
        "id": "5910bd93"
      },
      "source": [
        "\n",
        "## 3Ô∏è‚É£ Handle Missing Values\n",
        "Medical datasets often contain missing values.\n",
        "We use:\n",
        "- **Median** for continuous variables (robust to outliers)\n",
        "- **Mode** for binary/categorical features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83a314da",
      "metadata": {
        "id": "83a314da"
      },
      "outputs": [],
      "source": [
        "\n",
        "for col in [\"education\", \"cigsPerDay\", \"totChol\", \"BMI\", \"glucose\", \"heartRate\"]:\n",
        "    data[col] = data[col].fillna(data[col].median())\n",
        "\n",
        "data[\"BPMeds\"] = data[\"BPMeds\"].fillna(data[\"BPMeds\"].mode()[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "389b6e87",
      "metadata": {
        "id": "389b6e87"
      },
      "source": [
        "\n",
        "## 4Ô∏è‚É£ Feature / Target Split\n",
        "- **X** ‚Üí Input features\n",
        "- **y** ‚Üí Target (TenYearCHD)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e34531a",
      "metadata": {
        "id": "2e34531a"
      },
      "outputs": [],
      "source": [
        "\n",
        "X = data.drop(columns=[\"TenYearCHD\"])\n",
        "y = data[\"TenYearCHD\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58b68088",
      "metadata": {
        "id": "58b68088"
      },
      "source": [
        "\n",
        "## 5Ô∏è‚É£ Train-Test Split (Stratified)\n",
        "We use **stratification** to preserve class distribution\n",
        "because heart disease data is imbalanced.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66c6a7fc",
      "metadata": {
        "id": "66c6a7fc"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.25,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "582a5890",
      "metadata": {
        "id": "582a5890"
      },
      "source": [
        "\n",
        "## 6Ô∏è‚É£ Handle Class Imbalance\n",
        "XGBoost supports imbalance via `scale_pos_weight`.\n",
        "This prevents the model from ignoring minority (disease) cases.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04f60481",
      "metadata": {
        "id": "04f60481"
      },
      "outputs": [],
      "source": [
        "\n",
        "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
        "scale_pos_weight\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1add64a5",
      "metadata": {
        "id": "1add64a5"
      },
      "source": [
        "\n",
        "## 7Ô∏è‚É£ Hyperparameter Search ‚Äì Model A\n",
        "We use **RandomizedSearchCV** instead of GridSearch:\n",
        "- Faster\n",
        "- Better coverage of parameter space\n",
        "\n",
        "Scoring metric: **F1-score**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b57397f0",
      "metadata": {
        "id": "b57397f0"
      },
      "outputs": [],
      "source": [
        "\n",
        "param_grid = {\n",
        "    \"n_estimators\": randint(400, 1000),\n",
        "    \"learning_rate\": loguniform(0.01, 0.06),\n",
        "    \"max_depth\": randint(3, 6),\n",
        "    \"min_child_weight\": randint(4, 15),\n",
        "    \"gamma\": uniform(0.3, 2.0),\n",
        "    \"subsample\": uniform(0.6, 0.25),\n",
        "    \"colsample_bytree\": uniform(0.6, 0.25),\n",
        "    \"reg_lambda\": loguniform(0.8, 6.0),\n",
        "}\n",
        "\n",
        "grid = RandomizedSearchCV(\n",
        "    estimator=XGBClassifier(\n",
        "        objective=\"binary:logistic\",\n",
        "        eval_metric=\"aucpr\",\n",
        "        scale_pos_weight=scale_pos_weight,\n",
        "        random_state=42,\n",
        "        tree_method=\"hist\",\n",
        "        device=\"cuda\",\n",
        "        predictor=\"gpu_predictor\",\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "    param_distributions=param_grid,\n",
        "    scoring=\"f1\",\n",
        "    n_iter=100,\n",
        "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
        "    refit=True,\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26ae81b2",
      "metadata": {
        "id": "26ae81b2"
      },
      "source": [
        "\n",
        "## 8Ô∏è‚É£ Probability Calibration (Model A)\n",
        "Why calibration?\n",
        "- Raw ML probabilities are often **overconfident**\n",
        "- Medical decisions need **reliable probabilities**\n",
        "\n",
        "We use **Sigmoid Calibration (Platt Scaling)** with CV.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b36f329d",
      "metadata": {
        "id": "b36f329d"
      },
      "outputs": [],
      "source": [
        "\n",
        "best_xgb = grid.best_estimator_\n",
        "\n",
        "model_A = CalibratedClassifierCV(\n",
        "    estimator=best_xgb,\n",
        "    method=\"sigmoid\",\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "model_A.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2579b9f",
      "metadata": {
        "id": "a2579b9f"
      },
      "source": [
        "\n",
        "## 9Ô∏è‚É£ Threshold Optimization\n",
        "Default threshold (0.5) is not optimal for healthcare.\n",
        "We sweep thresholds to achieve **Recall ‚â• 75%**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89b14f92",
      "metadata": {
        "id": "89b14f92"
      },
      "outputs": [],
      "source": [
        "\n",
        "y_proba = model_A.predict_proba(X_test)[:, 1]\n",
        "\n",
        "best_threshold = None\n",
        "for t in np.arange(0.10, 0.51, 0.05):\n",
        "    y_tmp = (y_proba >= t).astype(int)\n",
        "    r = recall_score(y_test, y_tmp)\n",
        "    print(f\"threshold={t:.2f} | recall={r:.3f}\")\n",
        "    if r >= 0.75 and best_threshold is None:\n",
        "        best_threshold = t\n",
        "\n",
        "if best_threshold is None:\n",
        "    best_threshold = 0.25\n",
        "\n",
        "best_threshold\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5b509b0",
      "metadata": {
        "id": "f5b509b0"
      },
      "source": [
        "\n",
        "## üîü Final Evaluation ‚Äì Model A\n",
        "We evaluate using:\n",
        "- Confusion Matrix\n",
        "- Classification Report\n",
        "- ROC-AUC\n",
        "- PR-AUC\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "042bf657",
      "metadata": {
        "id": "042bf657"
      },
      "outputs": [],
      "source": [
        "\n",
        "y_pred = (y_proba >= best_threshold).astype(int)\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n",
        "print(\"PR-AUC :\", average_precision_score(y_test, y_proba))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56307579",
      "metadata": {
        "id": "56307579"
      },
      "source": [
        "\n",
        "## 1Ô∏è‚É£1Ô∏è‚É£ Model B ‚Äì Lightweight Model\n",
        "Uses fewer features for:\n",
        "- Faster inference\n",
        "- Easier data collection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed839d27",
      "metadata": {
        "id": "ed839d27"
      },
      "outputs": [],
      "source": [
        "\n",
        "MODEL_B_FEATURES = [\n",
        "    \"age\", \"male\", \"BMI\", \"sysBP\",\n",
        "    \"diaBP\", \"totChol\", \"glucose\", \"currentSmoker\"\n",
        "]\n",
        "\n",
        "X_b = data[MODEL_B_FEATURES]\n",
        "y_b = data[\"TenYearCHD\"]\n",
        "\n",
        "Xb_train, Xb_test, yb_train, yb_test = train_test_split(\n",
        "    X_b, y_b,\n",
        "    test_size=0.25,\n",
        "    stratify=y_b,\n",
        "    random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c353d342",
      "metadata": {
        "id": "c353d342"
      },
      "source": [
        "\n",
        "## 1Ô∏è‚É£2Ô∏è‚É£ Train, Calibrate & Evaluate Model B\n",
        "Same pipeline, fewer features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7542af66",
      "metadata": {
        "id": "7542af66",
        "outputId": "4c08d87f-295c-4efe-860b-983bc54176ab"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'yb_train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m scale_pos_weight_b = (\u001b[43myb_train\u001b[49m == \u001b[32m0\u001b[39m).sum() / (yb_train == \u001b[32m1\u001b[39m).sum()\n\u001b[32m      3\u001b[39m random_search_b = RandomizedSearchCV(\n\u001b[32m      4\u001b[39m     estimator=XGBClassifier(\n\u001b[32m      5\u001b[39m         objective=\u001b[33m\"\u001b[39m\u001b[33mbinary:logistic\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m     n_jobs=-\u001b[32m1\u001b[39m\n\u001b[32m     25\u001b[39m )\n\u001b[32m     27\u001b[39m random_search_b.fit(Xb_train, yb_train)\n",
            "\u001b[31mNameError\u001b[39m: name 'yb_train' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "scale_pos_weight_b = (yb_train == 0).sum() / (yb_train == 1).sum()\n",
        "\n",
        "random_search_b = RandomizedSearchCV(\n",
        "    estimator=XGBClassifier(\n",
        "        objective=\"binary:logistic\",\n",
        "        eval_metric=\"aucpr\",\n",
        "        scale_pos_weight=scale_pos_weight_b,\n",
        "        random_state=42,\n",
        "        tree_method=\"hist\",\n",
        "        device=\"cuda\",\n",
        "        predictor=\"gpu_predictor\",\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "    param_distributions={\n",
        "        \"n_estimators\": randint(100, 500),\n",
        "        \"learning_rate\": uniform(0.01, 0.2),\n",
        "        \"max_depth\": randint(3, 6)\n",
        "    },\n",
        "    n_iter=50,\n",
        "    scoring=\"f1\",\n",
        "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
        "    verbose=1,\n",
        "    refit=True,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "random_search_b.fit(Xb_train, yb_train)\n",
        "\n",
        "model_b = CalibratedClassifierCV(\n",
        "    estimator=random_search_b.best_estimator_,\n",
        "    method=\"sigmoid\",\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "model_b.fit(Xb_train, yb_train)\n",
        "\n",
        "yb_proba = model_b.predict_proba(Xb_test)[:, 1]\n",
        "yb_pred = (yb_proba >= 0.25).astype(int)\n",
        "\n",
        "print(confusion_matrix(yb_test, yb_pred))\n",
        "print(classification_report(yb_test, yb_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "636b710a",
      "metadata": {
        "id": "636b710a"
      },
      "source": [
        "\n",
        "## 1Ô∏è‚É£3Ô∏è‚É£ Save Models & Metadata\n",
        "Saved artifacts:\n",
        "- model_A.pkl / model_B.pkl\n",
        "- feature lists\n",
        "- decision thresholds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dbd315f",
      "metadata": {
        "id": "2dbd315f"
      },
      "outputs": [],
      "source": [
        "\n",
        "joblib.dump(model_A, \"model_A.pkl\")\n",
        "joblib.dump(model_b, \"model_B.pkl\")\n",
        "joblib.dump(X.columns.tolist(), \"model_a_features.pkl\")\n",
        "joblib.dump(MODEL_B_FEATURES, \"model_b_features.pkl\")\n",
        "joblib.dump(best_threshold, \"model_A_threshold.pkl\")\n",
        "joblib.dump(0.25, \"model_B_threshold.pkl\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}